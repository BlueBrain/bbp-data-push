"""
Create a 'Mesh' resource payload to push into Nexus. This script has been designed to 
function with brain region meshes generated by the Atlas pipeline.
To know more about 'Mesh' resources and Nexus, see https://bluebrainnexus.io.
Link to BBP Atlas pipeline confluence documentation: 
    https://bbpteam.epfl.ch/project/spaces/x/rS22Ag
"""

import os
import yaml
import fnmatch
from kgforge.core import Resource
from kgforge.specializations.stores.demo_store import DemoStore
from bba_data_push.commons import (
    get_brain_region_name,
    get_hierarchy_file,
    add_contribution,
    append_provenance_to_description,
)
from bba_data_push.logging import create_log_handler

L = create_log_handler(__name__, "./push_meshes.log")


def create_mesh_resources(
    forge,
    inputpath: list,
    config_path,
    input_hierarchy: list,
    provenances: list,
    verbose,
) -> list:
    """
    Construct the input brain mesh dataset property payloads that will be push with the
    corresponding files into Nexus as a resource.

    Parameters:
        forge : instantiated and configured forge object.
        inputpath : input datasets paths. These datasets are folder containing mesh
                    .obj files.
        config_path : configuration yaml file path containing the names and paths of
                      the atlas-pipeline generated datasets.
        input_hierarchy : path to the input hierarchy json file containing input
                          dataset brain regions hierarchy.
        provenances : string name of the module that generated input datasets.

    Returns:
        datasets : list containing as much Resource object as input datasets. Each
                   Resource is defined by an attached input file and its properties
                   described in a payload.
    """
    L.setLevel(verbose)

    # Constructs the payloads schema according to the 2 different possible mesh
    # dataset to be pushed
    config_file = open(config_path)
    config_content = yaml.safe_load(config_file.read().strip())
    config_file.close()
    try:
        mesh_path = config_content["GeneratedDatasetPath"]["MeshFile"]
    except KeyError as error:
        L.error(
            f"KeyError: {error}. The key ['GeneratedDatasetPath']['MeshFile'] is not "
            "found in the dataset configuration file"
        )
        exit(1)

    # Constants
    datasets = []
    module_prov = "parcellation2mesh"
    spatial_unit = "Âµm"
    atlas_reference_system_id = (
        "https://bbp.epfl.ch/neurosciencegraph/data/"
        "allen_ccfv3_spatial_reference_system"
    )
    id_atlas_release = (
        "https://bbp.epfl.ch/neurosciencegraph/data/"
        "e2e500ec-fe7e-4888-88b9-b72425315dda"
    )
    # Link to the spatial ref system
    isRegisteredIn = {
        "@type": ["BrainAtlasSpatialReferenceSystem", "AtlasSpatialReferenceSystem"],
        "@id": atlas_reference_system_id,
    }

    subject = {
        "@type": "Subject",
        "species": {
            "@id": "http://purl.obolibrary.org/obo/NCBITaxon_10090",
            "label": "Mus musculus",
        },
    }

    # Create contribution
    if isinstance(forge._store, DemoStore):
        contribution = []
    else:
        try:
            contribution, log_info = add_contribution(forge)
            L.info("\n".join(log_info))
        except Exception as e:
            L.error(f"Error: {e}")
            exit(1)

    # Constructs the Resource properties payloads accordingly to the input atlas Mesh
    # datasets
    for filepath in inputpath:
        flat_tree = {}
        if os.path.isdir(filepath):
            directory = filepath
            files = os.listdir(directory)
            pattern = "*.obj"
            files_mesh = fnmatch.filter(files, pattern)
            if not files_mesh:
                L.error(f"Error: '{filepath}' do not contain any .obj mesh files")
                exit(1)
            isMeshSplit = False
            try:
                if os.path.samefile(filepath, mesh_path["brain_region_meshes_hybrid"]):
                    hierarchy_tag = "hierarchy"
                elif os.path.samefile(
                    filepath, mesh_path["brain_region_meshes_l23split"]
                ):
                    hierarchy_tag = "hierarchy_l23split"
                else:
                    L.error(
                        f"Error: The '{filepath}' folder do not correspond to one of "
                        "the brain meshes folder dataset defined in the MeshFile "
                        "section of the 'generated dataset' configuration file"
                    )
                    exit(1)
            except FileNotFoundError as e:
                L.error(f"FileNotFoundError: {e}")
                exit(1)
        else:
            L.error(
                f"Error: '{filepath}' is not a directory. The input dataset need to be "
                "a directory containing OBJ brain meshes"
            )
            exit(1)

        # We create a 1st payload which will serve as template for the others
        meshpath = os.path.join(directory, files_mesh[0])
        try:
            region_id = int(os.path.splitext(os.path.basename(meshpath))[0])
        except ValueError as error:
            L.error(
                f"ValueError in {'meshpath'} file name. {error}. The mesh file names "
                "have to be integer representing their region"
            )
            exit(1)
        extension = os.path.splitext(os.path.basename(meshpath))[1][1:]

        try:
            hierarchy_path = get_hierarchy_file(
                input_hierarchy, config_content, hierarchy_tag
            )
            region_name, hierarchy_tree = get_brain_region_name(
                region_id, hierarchy_path, flat_tree
            )
        except KeyError as e:
            L.error(f"KeyError: {e}")
            exit(1)
        except ValueError as e:
            L.error(f"ValueError: {e}")
            exit(1)

        flat_tree = hierarchy_tree
        L.info(f"Pushing region {region_id}...")

        # We create a 1st payload that will be recycled in case of multiple files to
        # push
        content_type = f"application/{extension}"
        distribution_file = forge.attach(meshpath, content_type)

        brainLocation = {
            "brainRegion": {"@id": f"mba:{region_id}", "label": region_name},
            "atlasSpatialReferenceSystem": {
                "@type": [
                    "BrainAtlasSpatialReferenceSystem",
                    "AtlasSpatialReferenceSystem",
                ],
                "@id": atlas_reference_system_id,
            },
        }
        if isMeshSplit:
            mesh_description = (
                f"Brain region mesh - {region_name.title()} (ID: {region_id}). "
                "It is based in the parcellation volume resulting of the hybridation "
                "between CCFv2 and CCFv3 with the isocortex layer 2 and 3 split."
            )
        else:
            mesh_description = (
                f"Brain region mesh - {region_name.title()} (ID: {region_id}). "
                "It is based in the parcellation volume resulting of the hybridation "
                "between CCFv2 and CCFv3."
            )

        if provenances[0]:
            try:
                prov_description = append_provenance_to_description(
                    provenances, module_prov
                )
                mesh_description = f"{mesh_description} {prov_description}"
            except ValueError as e:
                L.error(f"Value Error in provenance content: {e}")
                exit(1)

        mesh_resource = Resource(
            type=["BrainParcellationMesh", "Mesh", "Dataset"],
            name=f"{region_name.title()} Mesh",
            description=mesh_description,
            atlasRelease={"@id": id_atlas_release},
            brainLocation=brainLocation,
            distribution=distribution_file,
            isRegisteredIn=isRegisteredIn,
            spatialUnit=spatial_unit,
            subject=subject,
            contribution=contribution,
        )
        # dataset = Dataset.from_resource(forge, mesh_resource, store_metadata=True)

        datasets = [mesh_resource]

        for f in range(1, len(files_mesh)):  # start at the 2nd file

            meshpath = os.path.join(directory, files_mesh[f])
            try:
                region_id = int(os.path.splitext(os.path.basename(meshpath))[0])
            except ValueError as error:
                L.error(
                    f"ValueError in {'meshpath'} file name. {error}. The mesh file "
                    "names have to be integer representing their region"
                )
                exit(1)
            try:
                region_name, hierarchy_tree = get_brain_region_name(
                    region_id, hierarchy_path, flat_tree
                )
            except KeyError as e:
                L.error(f"KeyError: {e}")
                exit(1)
            L.info(f"Pushing region {region_id}...")
            distribution_file = forge.attach(meshpath, content_type)
            brainLocation = {
                "brainRegion": {"@id": f"mba:{region_id}", "label": region_name},
                "atlasSpatialReferenceSystem": {
                    "@type": [
                        "BrainAtlasSpatialReferenceSystem",
                        "AtlasSpatialReferenceSystem",
                    ],
                    "@id": atlas_reference_system_id,
                },
            }
            if isMeshSplit:
                mesh_description = (
                    f"Brain region mesh - {region_name.title()} "
                    f"(ID: {region_id}). It is based in the parcellation volume "
                    "resulting of the hybridation between CCFv2 and CCFv3 and "
                    "integrating the splitting of layer 2 and layer 3."
                )
            else:
                mesh_description = (
                    f"Brain region mesh - {region_name.title()} "
                    f"(ID: {region_id}). It is based in the parcellation volume "
                    "resulting of the hybridation between CCFv2 and CCFv3."
                )
            if provenances[0]:
                mesh_description = f"{mesh_description} {prov_description}"

            mesh_resources = Resource(
                type=mesh_resource.type,
                name=f"{region_name.title()} Mesh",
                description=mesh_description,
                atlasRelease=mesh_resource.atlasRelease,
                isRegisteredIn=mesh_resource.isRegisteredIn,
                brainLocation=brainLocation,
                spatialUnit=mesh_resource.spatialUnit,
                distribution=distribution_file,
                contribution=mesh_resource.contribution,
                subject=mesh_resource.subject,
            )
            # dataset = Dataset.from_resource(forge, mesh_resources,
            # store_metadata=True)
            datasets.append(mesh_resources)

    return datasets
